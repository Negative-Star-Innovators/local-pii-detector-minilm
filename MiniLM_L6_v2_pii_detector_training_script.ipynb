{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Dependencies\n",
        "Let's start by installing the necessary libraries from the Hugging Face ecosystem. We need `transformers` for the model, `datasets` to download the Nemotron-PII data, `evaluate` and `seqeval` for calculating our NER evaluation metrics, and `accelerate` to optimize the PyTorch training loop."
      ],
      "metadata": {
        "id": "dQnznLgVrufs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIeFv5esW0Es"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets seqeval evaluate accelerate -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configuration & Data Loading\n",
        "Here we define our base model (`all-MiniLM-L6-v2`) and the dataset we want to fine-tune on (`nvidia/Nemotron-PII`). We also set a max sequence length of 512 tokens. Since we are training a Token Classification model, we will load both the train and test splits, concatenate them, and shuffle them into a clean 90/10 Train/Validation split."
      ],
      "metadata": {
        "id": "U70gqyEXsNNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import evaluate\n",
        "\n",
        "# 1. Settings\n",
        "MODEL_CHECKPOINT = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "DATASET_NAME = \"nvidia/Nemotron-PII\"\n",
        "MAX_LENGTH = 512\n",
        "\n",
        "# 2. Load Data\n",
        "print(\"\\n Downloading dataset...\")\n",
        "train_split = load_dataset(DATASET_NAME, split=\"train\")\n",
        "test_split = load_dataset(DATASET_NAME, split=\"test\")\n",
        "raw_datasets = concatenate_datasets([train_split, test_split])\n",
        "raw_datasets = raw_datasets.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "\n",
        "print(f\"Training on {len(raw_datasets['train'])} samples\")"
      ],
      "metadata": {
        "id": "CJkkW87Lcazk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preprocessing & Token Alignment\n",
        "Token Classification (NER) requires labels to align perfectly with the tokenized text. The `Nemotron-PII` dataset stores entity spans as stringified dictionaries, so we first iterate through the dataset and safely parse them using `ast.literal_eval` to extract all unique PII categories.\n",
        "\n",
        "Next, we map our character-level entity spans to the model's subword tokens using the standard **BIO (Begin, Inside, Outside)** tagging format. The `tokenize_and_align_labels` function ensures that special tokens (like `[CLS]` or `[SEP]`) are ignored during loss calculation (labeled as `-100`)."
      ],
      "metadata": {
        "id": "E54X-8xosQdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import json\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "# The dataset stores spans as strings, so we must parse them first.\n",
        "unique_labels = set()\n",
        "\n",
        "# We iterate carefully to avoid the TypeError\n",
        "for spans_string in raw_datasets[\"train\"][\"spans\"]:\n",
        "    # Safely convert string representation \"[{'start':...}]\" to a Python list\n",
        "    try:\n",
        "        spans = ast.literal_eval(spans_string)\n",
        "        for span in spans:\n",
        "            unique_labels.add(span[\"label\"])\n",
        "    except (ValueError, SyntaxError):\n",
        "        continue\n",
        "\n",
        "label_list = sorted(list(unique_labels))\n",
        "bio_label_list = [\"O\"]\n",
        "for label in label_list:\n",
        "    bio_label_list.append(f\"B-{label}\")\n",
        "    bio_label_list.append(f\"I-{label}\")\n",
        "\n",
        "id2label = {i: label for i, label in enumerate(bio_label_list)}\n",
        "label2id = {label: i for i, label in enumerate(bio_label_list)}\n",
        "\n",
        "print(f\"Labels found: {label_list}\")\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        is_split_into_words=False,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over every document in the batch\n",
        "    for i, offsets in enumerate(tokenized_inputs[\"offset_mapping\"]):\n",
        "        doc_labels = []\n",
        "\n",
        "        # --- CORRECTION HERE AS WELL ---\n",
        "        # Parse the stringified spans for this specific example\n",
        "        raw_spans = examples[\"spans\"][i]\n",
        "        try:\n",
        "            spans = ast.literal_eval(raw_spans)\n",
        "        except:\n",
        "            spans = []\n",
        "\n",
        "        # Sort spans by start index\n",
        "        spans = sorted(spans, key=lambda x: x[\"start\"])\n",
        "\n",
        "        for idx, (start, end) in enumerate(offsets):\n",
        "            # Special tokens (CLS, SEP, PAD)\n",
        "            if start == end:\n",
        "                doc_labels.append(-100)\n",
        "                continue\n",
        "\n",
        "            token_label = \"O\"\n",
        "\n",
        "            # Check if token falls inside a span\n",
        "            for span in spans:\n",
        "                if start >= span[\"start\"] and end <= span[\"end\"]:\n",
        "                    if start == span[\"start\"]:\n",
        "                        token_label = f\"B-{span['label']}\"\n",
        "                    else:\n",
        "                        token_label = f\"I-{span['label']}\"\n",
        "                    break\n",
        "\n",
        "            doc_labels.append(label2id[token_label])\n",
        "\n",
        "        labels.append(doc_labels)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "id": "m5q_u6FqcjEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Initialize Model & Evaluation Metrics\n",
        "Now we load the pre-trained `MiniLM-L6-v2` base model and replace its standard pooling head with a Token Classification head. We pass `ignore_mismatched_sizes=True` because we are introducing a new classification layer specific to the size of our BIO label list.\n",
        "\n",
        "We also define our `compute_metrics` function, which uses the `seqeval` library. During training, this will automatically calculate Precision, Recall, F1 Score, and Accuracy at the end of each epoch, ignoring the `-100` padding tokens."
      ],
      "metadata": {
        "id": "lV4CHgNSsSNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the sentence transformer as a Token Classification model\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    MODEL_CHECKPOINT,\n",
        "    num_labels=len(bio_label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True # Necessary when reshaping the head\n",
        ")\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [bio_label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [bio_label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "S9Hx6T-hdncr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training Setup & Execution\n",
        "Because cloud environments (like Colab) can disconnect unexpectedly, we'll mount Google Drive and save our checkpoints directly there.\n",
        "\n",
        "We define our `TrainingArguments` (setting a learning rate of 2e-5, batch sizes of 64, and training for 4 epochs) and initialize the Hugging Face `Trainer`. The script includes smart logic to check your Drive folder and automatically resume from the latest checkpoint if training was previously interrupted.\n"
      ],
      "metadata": {
        "id": "MHcukpGqsTtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive to save checkpoints persistently\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define a path in your Google Drive\n",
        "# Change 'pii-detector-checkpoints' to whatever folder name you prefer\n",
        "drive_output_dir = \"/content/drive/MyDrive/pii-detector-checkpoints\"\n",
        "\n",
        "# 2. Update Training Arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=drive_output_dir,  # Save DIRECTLY to Google Drive\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",        # Save a checkpoint at the end of every epoch\n",
        "    save_total_limit=3,           # Only keep the last 3 epochs to save Drive space (optional)\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,  # At the very end, load the best epoch based on metrics\n",
        "    metric_for_best_model=\"f1\"    # Use F1 score to determine the \"best\" model\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=DataCollatorForTokenClassification(tokenizer),\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 3. Logic to Resume Training\n",
        "# Check if there are existing checkpoints in the Drive folder\n",
        "files_in_drive = os.listdir(drive_output_dir) if os.path.exists(drive_output_dir) else []\n",
        "checkpoint_exists = any(\"checkpoint\" in f for f in files_in_drive)\n",
        "\n",
        "if checkpoint_exists:\n",
        "    print(f\"Checkpoints found in {drive_output_dir}. Resuming training...\")\n",
        "    trainer.train(resume_from_checkpoint=True)\n",
        "else:\n",
        "    print(\"No checkpoints found. Starting fresh training...\")\n",
        "    trainer.train()"
      ],
      "metadata": {
        "id": "qin-nUrHcdy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Save and Export the Final Model\n",
        "Once training is complete, we save the final, best-performing model and its tokenizer directly to Google Drive for safekeeping.\n",
        "\n",
        "Finally, the script optionally zips the completed model directory and downloads it directly to your local machine. From here, you can run inference locally, convert it to ONNX, or upload the directory to a Hugging Face model repository."
      ],
      "metadata": {
        "id": "bexl4Y59sVrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# 1. Define final save path (Inside Drive for safety)\n",
        "final_save_path = \"/content/drive/MyDrive/pii_detector_final_model\"\n",
        "\n",
        "# 2. Save the final model artifacts\n",
        "trainer.save_model(final_save_path)\n",
        "tokenizer.save_pretrained(final_save_path)\n",
        "\n",
        "print(f\"Model successfully saved to: {final_save_path}\")\n",
        "\n",
        "# Optional: If you still want to download it to your local machine as a ZIP\n",
        "shutil.make_archive(\"/content/pii_detector_model\", 'zip', final_save_path)\n",
        "from google.colab import files\n",
        "files.download(\"/content/pii_detector_model.zip\")"
      ],
      "metadata": {
        "id": "_rTGNpSXf8b1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}